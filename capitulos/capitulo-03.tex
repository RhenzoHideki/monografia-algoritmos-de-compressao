\chapter{Desenvolvimento}\label{cap:desenvolvimento}

Este capítulo descreve o desenvolvimento dos módulos LZ77 e codificação
aritmética na biblioteca \textit{Komm}. A implementação foi realizada em
Python, linguagem-base do projeto.

\section{Módulo LZ77}

Esta seção documenta a implementação do algoritmo \textit{Lempel–Ziv 77} (LZ77)
na \textit{Komm}, cobrindo decisões de projeto, integração e validação. A
biblioteca já inclui diversos esquemas de compressão sem perdas (Huffman,
Tunstall, LZ78 e LZW), e a contribuição aqui foi a implementação completa do
LZ77 com foco tanto prático quanto didático.

\subsection{Objetivos e escopo}

Os objetivos deste módulo foram:
\begin{itemize}
    \item implementar as rotinas de codificação (\texttt{encode}) e decodificação
          (\texttt{decode}) gerando \textbf{tokens} no formato \((p,\ell,x)\);
    \item integrar a classe ao padrão já utilizado, documentação e testes da \textit{Komm};
    \item disponibilizar uma \textbf{pipeline modular} para fins educacionais,
          viabilizando a inspeção de resultados intermediários e a comparação com
          exemplos da literatura (que, em geral, não mostram a saída em base binária).
\end{itemize}

\subsection{Janela deslizante e notação}\label{subsec:janela-notacao}

Adotamos a notação usadas nas bibliografias que foram utilizadas para o estudo do algoritmo LZ77:
\[
    W = S + L,
\]
onde \(S\) é o tamanho do \emph{search buffer}, \(L\) é o tamanho do
\emph{lookahead buffer} e \(W\) é o tamanho total da janela. Denotamos por \(
|\mathcal{X}| \) a cardinalidade do alfabeto de \textbf{entrada} e por \(
|\mathcal{Y}| \) a cardinalidade do alfabeto de \textbf{saída}.

Cada token tem o formato
\[
    (p,\ell,x),
\]
em que \(p\) é o \textit{pointer} (deslocamento no \emph{search buffer}),
\(\ell\) é o comprimento da ocorrência e \(x\in \mathcal{X}\) é o símbolo
literal subsequente.

\paragraph*{Origem do ponteiro.}
Neste trabalho, seguindo o artigo original do LZ77, \(p\) é medido a partir do \textbf{início} do \emph{search buffer}. \emph{Observação}: algumas implementações didáticas medem a partir do \textbf{fim} do \emph{search buffer}; ambas convenções aparecem na literatura. Mantemos a primeira e documentamos a diferença quando necessário.

\subsection{Arquitetura e estrutura da implementação}

A classe \texttt{LempelZiv77Code} concentra a lógica do algoritmo e expõe a classe da seguinte maneira:
\begin{lstlisting}[language=Python, caption={Estrutura simplificada da classe LZ77}]
@dataclass
class LempelZiv77Code:
    source_cardinality: int      # |X|
    target_cardinality: int      # |Y|
    window_size: int             # W
    lookahead_size: int          # L (logo S = W - L)

    def encode(self, data): ...
    def decode(self, encoded): ...
\end{lstlisting}

Exemplo de uso:
\begin{lstlisting}[language=Python, caption={Uso típico do LZ77 na \textit{Komm}}]
lz77 = LempelZiv77Code(
    source_cardinality=256,     # |X|
    target_cardinality=2,       # |Y| (binário)
    window_size=32768,          # W
    lookahead_size=258          # L (então S = 32510)
)
encoded = lz77.encode(b"... dados ...")
decoded = lz77.decode(encoded)
assert decoded == b"... dados ..."
\end{lstlisting}


Com intuito pedagógico, a pipeline foi dividida em \textbf{quatro} módulos
internos — dois para \texttt{encode} e dois para \texttt{decode}:
\begin{enumerate}
    \item \textbf{Codificação}
          \begin{itemize}
              \item \texttt{source\_to\_tokens}: identifica os tokens \((p,\ell,x)\) sobre a janela \(W=S+L\);
              \item \texttt{tokens\_to\_target}: mapeia os tokens para o fluxo no alfabeto de saída \(\mathcal{Y}\).
          \end{itemize}
    \item \textbf{Decodificação}
          \begin{itemize}
              \item \texttt{target\_to\_tokens}: reconstrói os tokens a partir do fluxo em \(\mathcal{Y}\);
              \item \texttt{tokens\_to\_source}: recompõe a sequência original em \(\mathcal{X}\).
          \end{itemize}
\end{enumerate}

Essa organização favorece: (i) clareza didática; (ii) comparação direta com
esquemas de manuais/artigos; e (iii) inspeção de saídas intermediárias
(inclusive em binário), recurso raramente mostrado na literatura.

\subsection{Larguras de campos na saída}\label{subsec:larguras}

Seja a saída codificada em base \( |\mathcal{Y}| \). As larguras (em símbolos
do alfabeto de saída) dos campos do token são:
\[
    w_p = \big\lceil \log_{|\mathcal{Y}|} S \big\rceil,\qquad
    w_\ell = \big\lceil \log_{|\mathcal{Y}|} L \big\rceil,\qquad
    w_x = \big\lceil \log_{|\mathcal{Y}|} |\mathcal{X}| \big\rceil,
\]
e o custo total por token é
\[
    n \;=\; w_p + w_\ell + w_x.
\]

\subsection{Testes e validação}\label{subsec:testes}

Os testes unitários (\texttt{test\_lz77.py}) cobrem:
\begin{itemize}
    \item cadeias com alta redundância e com sobreposição;
    \item exemplos reproduzidos da literatura.
\end{itemize}
A validação principal usa \textit{round trip} (\(\texttt{decode}(\texttt{encode}(x)) = x\)) e compara tokens/fluxos intermediários com os parâmetros \((W,S,L)\) e larguras \((w_p,w_\ell,w_x)\).


