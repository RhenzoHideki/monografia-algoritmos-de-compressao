\chapter{Desenvolvimento}\label{cap:desenvolvimento}

Este capítulo descreve o desenvolvimento do módulo \texttt{LempelZiv77Code},
integrado à biblioteca \textit{Komm}. A implementação foi realizada em Python,
linguagem-base do projeto, buscando equilíbrio entre clareza didática e
conformidade com a arquitetura existente da biblioteca.

\section{Módulo LZ77}

Esta seção detalha a implementação do algoritmo \textit{Lempel–Ziv 77} (LZ77),
conforme descrito originalmente por Ziv e Lempel~\cite{1055714}, e sua
integração na biblioteca \textit{Komm}\footnote{\url{https://komm.dev/ref/LempelZiv77Code}}.
A \textit{Komm} já disponibiliza diversos esquemas de compressão sem perdas,
como Huffman, Tunstall, LZ78 e LZW, mas ainda não possuía uma implementação do
LZ77. Assim, a principal contribuição deste trabalho foi o desenvolvimento de
uma versão completa e modular do algoritmo, com foco tanto prático quanto
educacional.

\subsection{Objetivos e escopo}

Os objetivos deste módulo foram:
\begin{itemize}
    \item implementar as rotinas de codificação (\texttt{encode}) e decodificação
          (\texttt{decode}), compatíveis com o padrão interno da \textit{Komm};
    \item expor funções intermediárias para inspeção didática, permitindo a
          visualização dos tokens gerados e dos fluxos de dados nas diferentes etapas;
    \item validar a corretude do módulo por meio de testes unitários e de
          \emph{round trip} (\texttt{decode(encode(x)) == x});
    \item documentar e integrar o código ao padrão da biblioteca.
\end{itemize}

\subsection{Como utilizar}

A classe \texttt{LempelZiv77Code} implementa a codificação e decodificação
completa do algoritmo. Sua utilização segue o mesmo formato das demais classes
de codificação da \textit{Komm}. O construtor requer quatro parâmetros principais:
a cardinalidade do alfabeto de entrada (\texttt{source\_cardinality}),
a cardinalidade do alfabeto de saída (\texttt{target\_cardinality}),
o tamanho da janela deslizante total (\texttt{window\_size}) e o tamanho do
\textit{lookahead buffer} (\texttt{lookahead\_size}). Opcionalmente, pode-se
fornecer um conteúdo inicial para o \textit{search buffer}, útil em experimentos
ou testes.

\begin{lstlisting}[language=Python, caption={Exemplo de utilização do \textit{LZ77} na biblioteca \textit{Komm}.}]
import komm

# Instanciação do codificador
lz77 = komm.LempelZiv77Code(
    window_size=13,
    lookahead_size=6,
    source_cardinality=256,
    target_cardinality=2
)

# Exemplo de sequência de entrada
source = [ord(x) for x in "cabracadabrarrarrad"]

# Codificação e decodificação
encoded = lz77.encode(source)
decoded = lz77.decode(encoded)

assert decoded == source
\end{lstlisting}

O método \texttt{encode()} retorna o fluxo comprimido no alfabeto de saída
\(\mathcal{Y}\), enquanto \texttt{decode()} reconstrói a sequência original no
alfabeto de entrada \(\mathcal{X}\). Para análise intermediária, a classe expõe
os métodos \texttt{source\_to\_tokens()} e \texttt{tokens\_to\_source()}, que
convertem a sequência de entrada em uma lista de tokens
\(\langle p, \ell, x \rangle\) e vice-versa.

\begin{lstlisting}[language=Python, caption={Conversão intermediária entre sequência e tokens.}]
tokens = lz77.source_to_tokens(source)
print(tokens)
# [(6, 0, 100), (0, 4, 114), (4, 5, 100)]

reconstructed = lz77.tokens_to_source(tokens)
assert reconstructed == source
\end{lstlisting}

Esses métodos são especialmente úteis em contextos acadêmicos, pois permitem
acompanhar o comportamento do codificador em cada estágio do processo.

\subsection{Como foi feito}

A arquitetura do módulo segue o padrão das demais classes de codificação da
biblioteca. O código foi estruturado em quatro submódulos internos: dois
relacionados à etapa de codificação e dois à etapa de decodificação.

\begin{enumerate}
    \item \textbf{Codificação:}
          \begin{itemize}
              \item \texttt{source\_to\_tokens}: converte a sequência de entrada
              em tokens \((p,\ell,x)\);
              \item \texttt{tokens\_to\_target}: transforma os tokens no fluxo
              final no alfabeto \(\mathcal{Y}\).
          \end{itemize}
    \item \textbf{Decodificação:}
          \begin{itemize}
              \item \texttt{target\_to\_tokens}: reverte o fluxo comprimido de volta aos tokens;
              \item \texttt{tokens\_to\_source}: reconstrói a sequência original
              em \(\mathcal{X}\).
          \end{itemize}
\end{enumerate}

Essa separação permite maior legibilidade, facilita testes unitários e torna a
implementação mais transparente para uso didático e comparações com versões
descritas na literatura.

\subsection{Processo de busca na codificação (\texttt{source\_to\_tokens})}

O núcleo da codificação LZ77 está no método \texttt{source\_to\_tokens()}, que
busca, dentro do \textit{search buffer}, o maior trecho que coincida com o
prefixo do \textit{lookahead buffer}. Nesta implementação, a busca é feita de
forma simples e eficiente, utilizando o método \texttt{rfind()} da classe
\texttt{bytes} do Python — o que resulta em código mais limpo e
desempenho superior sem o uso explícito de tabelas de hash.

A cada iteração, o algoritmo:
\begin{enumerate}
    \item define o \textit{search buffer} como o trecho de tamanho \(S=W-L\);
    \item tenta localizar a sequência mais longa do \textit{lookahead} dentro do
    \textit{search buffer};
    \item emite o token \(\langle p, \ell, x \rangle\), onde \(p\) é o ponteiro
    (posição a partir do início da janela), \(\ell\) é o comprimento da
    correspondência e \(x\) é o próximo símbolo literal.
\end{enumerate}

Essa abordagem segue a convenção do artigo original de Ziv e Lempel, em que o
ponteiro \(p\) é medido a partir do início da janela, diferindo da convenção
moderna (offset medido a partir do fim do \textit{search buffer}). A utilização
do \texttt{rfind()} simplifica a busca, preservando a corretude e a clareza do
código.

\subsection{Testes e validação}

Os testes unitários\footnote{\url{https://github.com/rwnobrega/komm/blob/main/tests/lossless_coding/test_lz77.py}}
abrangem tanto casos básicos quanto exemplos reproduzidos da literatura,
verificando:
\begin{itemize}
    \item a corretude da codificação e decodificação (\emph{round trip});
    \item o comportamento com sobreposição de trechos (\emph{overlap});
    \item a consistência dos tokens gerados em diferentes tamanhos de janela e
    \textit{lookahead}.
\end{itemize}

Os resultados confirmam a consistência e compatibilidade do módulo com o padrão
de codificação da \textit{Komm}, assegurando sua integração com os demais
algoritmos já presentes na biblioteca.
