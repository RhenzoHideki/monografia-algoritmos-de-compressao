\chapter{Desenvolvimento}\label{cap:desenvolvimento}

Este capítulo descreve o desenvolvimento do módulo \texttt{LempelZiv77Code},
integrado à biblioteca \textit{Komm}. A implementação foi realizada em Python,
linguagem-base do projeto, buscando equilíbrio entre clareza didática e
conformidade com a arquitetura existente da biblioteca.

\section{Módulo LZ77}

Esta seção detalha a implementação do algoritmo \textit{Lempel–Ziv 77} (LZ77),
conforme descrito originalmente por Ziv e Lempel~\cite{1055714}, e sua
integração na biblioteca \textit{Komm}\footnote{\url{https://komm.dev/ref/LempelZiv77Code}}.
A \textit{Komm} já disponibiliza diversos esquemas de compressão sem perdas,
como Huffman, Tunstall, LZ78 e LZW, mas ainda não possuía uma implementação do
LZ77. Assim, a principal contribuição deste trabalho foi o desenvolvimento de
uma versão completa e modular do algoritmo, com foco tanto prático quanto
educacional.

\subsection{Objetivos e escopo}

Os objetivos deste módulo foram:
\begin{itemize}
    \item implementar as rotinas de codificação (\texttt{encode}) e decodificação
          (\texttt{decode}), compatíveis com o padrão interno da \textit{Komm};
    \item expor funções intermediárias para inspeção didática, permitindo a
          visualização dos tokens gerados e dos fluxos de dados nas diferentes etapas;
    \item validar a corretude do módulo  por meio de testes unitários e de
          \emph{round trip} \newline (\texttt{decode(encode(x)) == x});
    \item documentar e integrar o código ao padrão da biblioteca.
\end{itemize}

\subsection{Como utilizar}

A classe \texttt{LempelZiv77Code} implementa a codificação e decodificação
completa do algoritmo. Sua utilização segue o mesmo formato das demais classes
de codificação da \textit{Komm}. O construtor requer quatro parâmetros principais:
a cardinalidade do alfabeto de entrada (\texttt{source\_cardinality}),
a cardinalidade do alfabeto de saída (\texttt{target\_cardinality}),
o tamanho da janela deslizante total (\texttt{window\_size}) e o tamanho do
\textit{lookahead buffer} (\texttt{lookahead\_size}). Opcionalmente, pode-se
fornecer um conteúdo inicial para o \textit{search buffer}, útil em experimentos
ou testes.

\begin{lstlisting}[language=Python, caption={Exemplo de utilização do \textit{LZ77} na biblioteca \textit{Komm}.}]
import komm

# Instanciação do codificador
lz77 = komm.LempelZiv77Code(
    window_size=13,
    lookahead_size=6,
    source_cardinality=256,
    target_cardinality=2
)

# Exemplo de sequência de entrada
source = [ord(x) for x in "cabracadabrarrarrad"]

# Codificação e decodificação
encoded = lz77.encode(source)
decoded = lz77.decode(encoded)

assert decoded == source
\end{lstlisting}

O método \texttt{encode()} retorna o fluxo comprimido no alfabeto de saída
\(\mathcal{Y}\), enquanto \texttt{decode()} reconstrói a sequência original no
alfabeto de entrada \(\mathcal{X}\). Para análise intermediária, a classe expõe
os métodos \texttt{source\_to\_tokens()} e \texttt{tokens\_to\_source()}, que
convertem a sequência de entrada em uma lista de tokens
\(\langle p, \ell, x \rangle\) e vice-versa.

\begin{lstlisting}[language=Python, caption={Conversão intermediária entre sequência e tokens.}]
tokens = lz77.source_to_tokens(source)
print(tokens)
# [(6, 0, 100), (0, 4, 114), (4, 5, 100)]

reconstructed = lz77.tokens_to_source(tokens)
assert reconstructed == source
\end{lstlisting}

Esses métodos são especialmente úteis em contextos acadêmicos, pois permitem
acompanhar o comportamento do codificador em cada estágio do processo.

\subsection{Como foi feito}

A arquitetura do módulo segue o padrão das demais classes de codificação da
biblioteca. A classe foi estruturada em quatro métodos internos: dois
relacionados à etapa de codificação e dois à etapa de decodificação.

\begin{enumerate}
    \item \textbf{Codificação:}
          \begin{itemize}
              \item \texttt{source\_to\_tokens}: converte a sequência de entrada
              em tokens \((p,\ell,x)\);
              \item \texttt{tokens\_to\_target}: transforma os tokens no fluxo
              final no alfabeto \(\mathcal{Y}\).
          \end{itemize}
    \item \textbf{Decodificação:}
          \begin{itemize}
              \item \texttt{target\_to\_tokens}: reverte o fluxo comprimido de volta aos tokens;
              \item \texttt{tokens\_to\_source}: reconstrói a sequência original
              em \(\mathcal{X}\).
          \end{itemize}
\end{enumerate}

Essa separação permite maior legibilidade, facilita testes unitários e torna a
implementação mais transparente para uso didático e comparações com versões
descritas na literatura.

\subsection{Processo de busca na codificação (\texttt{source\_to\_tokens})}

O núcleo da codificação LZ77 está concentrado no método
\texttt{source\_to\_tokens()}, responsável por identificar, dentro do
\textit{search buffer}, o maior trecho que coincide com o prefixo do
\textit{lookahead buffer}. Nesta implementação, a busca é realizada de forma
simples e eficiente por meio do método \texttt{rfind()} da classe
\texttt{bytes} do Python, o que resulta em um código conciso e um desempenho
aceitável, mesmo sem recorrer a estruturas auxiliares complexas, como tabelas
de dispersão (\textit{hash tables}).

A cada iteração, o algoritmo:
\begin{enumerate}
    \item define o \textit{search buffer} como o trecho de tamanho \(S = W - L\);
    \item procura, dentro desse trecho, o maior sufixo que coincide com o
    prefixo atual do \textit{lookahead buffer};
    \item emite o token \(\langle p, \ell, x \rangle\), em que \(p\) é o ponteiro
    (posição a partir do início da janela), \(\ell\) é o comprimento da
    correspondência e \(x\) é o próximo símbolo literal.
\end{enumerate}

Essa abordagem segue a convenção original de Ziv e Lempel~\cite{1055714},
medindo o ponteiro \(p\) a partir do início do \textit{search buffer}, em
contraste com algumas implementações modernas que utilizam o deslocamento a
partir do final do buffer. A utilização do \texttt{rfind()} preserva a clareza
e a corretude do algoritmo, permitindo a reprodução fiel dos resultados
conceituais do LZ77, conforme apresentado no artigo de 1977.

No entanto, é importante observar que o uso de \texttt{rfind()} representa uma
busca direta por comparação de cadeias, sem otimizações adicionais de
indexação. Implementações voltadas a desempenho, como as presentes em
bibliotecas escritas em C (por exemplo, \textit{FastLZ}), ou abordagens
discutidas por \textcite{coderspirit2023lz77}, utilizam tabelas de hash para
armazenar ocorrências de subsequências de comprimento fixo, permitindo localizar
candidatos de correspondência de forma muito mais rápida. Nesses casos, a busca
é reduzida a poucas operações de leitura e comparação, ao custo de maior uso de
memória.

Assim, a implementação proposta na \textit{Komm} prioriza a legibilidade e a
adesão ao modelo teórico clássico, enquanto reconhece que técnicas como o uso
de \textit{hash tables} podem ter melhor desempenho sem alterar o comportamento lógico do algoritmo.


\subsection{Testes e validação}

Os testes unitários\footnote{\url{https://github.com/rwnobrega/komm/blob/main/tests/lossless_coding/test_lz77.py}}
abrangem tanto casos básicos quanto exemplos reproduzidos da literatura,
verificando:
\begin{itemize}
    \item a corretude da codificação e decodificação (\emph{round trip});
    \item o comportamento com sobreposição de trechos (\emph{overlap});
    \item a consistência dos tokens gerados em diferentes tamanhos de janela e
    \textit{lookahead}.
\end{itemize}

Os resultados confirmam a consistência e compatibilidade do módulo com o padrão
de codificação da \textit{Komm}, assegurando sua integração com os demais
algoritmos já presentes na biblioteca.

A seguir, apresenta-se um dos testes unitários mais representativos, baseado no
exemplo do livro de Sayood~\cite{sayood2012introduction}, que verifica a
correspondência entre a sequência original e o conjunto de tokens gerados:

\begin{lstlisting}[language=Python, caption={Teste unitário baseado no exemplo de Sayood (p. 122).}]
def test_lz77_sayood():
    # [Sayood, p. 122]
    code = komm.LempelZiv77Code(
        window_size=13,
        lookahead_size=6,
        source_cardinality=256,
        search_buffer=[ord(x) for x in "cabraca"],
    )
    source = [ord(x) for x in "dabrarrarrad"]
    expected = [(1, 0, "d"), (7, 4, "r"), (3, 5, "d")]
    tokens = []
    for offset, length, symbol in expected:
        tokens.append((7 - offset, length, ord(symbol)))
    np.testing.assert_equal(code.source_to_tokens(source), tokens)
    np.testing.assert_equal(code.tokens_to_source(tokens), source)
    np.testing.assert_equal(code.decode(code.encode(source)), source)
\end{lstlisting}

Esse teste reproduz o exemplo da codificação de
\texttt{"cabracadabrarrarrad"}, utilizando o mesmo tamanho de janela e
\textit{lookahead} definidos por Sayood. O teste verifica três propriedades
centrais do algoritmo:
\begin{enumerate}
    \item a geração correta dos tokens \(\langle p, \ell, x \rangle\);
    \item a reconstrução exata da sequência original a partir dos tokens;
    \item a preservação da integridade na operação composta
          \(\texttt{decode(encode(x)) = x}\).
\end{enumerate}

A validação automática por meio dos testes unitários demonstra que a
implementação segue fielmente a definição formal do LZ77 e mantém compatibilidade
total com o padrão de codificação utilizado na \textit{Komm}.
